#!/usr/bin/env python3
"""
Script test cáº¥u hÃ¬nh má»›i cho crawler .gov.vn
"""

import os
import json
import re
import requests
from urllib.parse import urljoin, urlparse
from bs4 import BeautifulSoup

def load_config():
    """Load cáº¥u hÃ¬nh tá»« cÃ¡c file config"""
    config_dir = 'config'
    
    def _load_list(path):
        with open(path, 'r', encoding='utf-8') as f:
            if path.endswith('.json'):
                return json.load(f)
            return [line.strip() for line in f if line.strip()]
    
    return {
        'domains': set(_load_list(os.path.join(config_dir, 'allow_domains.json'))),
        'keywords': [k.lower() for k in _load_list(os.path.join(config_dir, 'keywords.txt'))],
        'seeds': _load_list(os.path.join(config_dir, 'seeds.json')),
        'url_regex': [re.compile(p, re.I) for p in _load_list(os.path.join(config_dir, 'url_allow_regex.json'))]
    }

def is_allowed_url(url, url_regex):
    """Kiá»ƒm tra URL cÃ³ Ä‘Æ°á»£c phÃ©p khÃ´ng"""
    return any(r.match(url) for r in url_regex)

def get_domain(url):
    """Láº¥y domain tá»« URL"""
    return urlparse(url).netloc.replace('www.', '')

def has_relevant_keywords(text, keywords):
    """Kiá»ƒm tra text cÃ³ chá»©a tá»« khÃ³a liÃªn quan khÃ´ng"""
    text_lower = text.lower()
    found_keywords = [k for k in keywords if k in text_lower]
    return found_keywords

def test_url(url, config):
    """Test má»™t URL xem cÃ³ phÃ¹ há»£p vá»›i cáº¥u hÃ¬nh khÃ´ng"""
    print(f"\nğŸ” Testing: {url}")
    
    # Check domain
    domain = get_domain(url)
    if domain not in config['domains']:
        print(f"   âŒ Domain '{domain}' khÃ´ng trong danh sÃ¡ch cho phÃ©p")
        return False
    
    # Check URL regex
    if not is_allowed_url(url, config['url_regex']):
        print(f"   âŒ URL khÃ´ng match vá»›i regex patterns")
        return False
    
    print(f"   âœ… Domain vÃ  URL pattern há»£p lá»‡")
    
    # Try to fetch content
    try:
        response = requests.get(url, timeout=10, headers={
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # Get title and text content
        title = soup.find('title')
        title_text = title.get_text().strip() if title else ""
        
        # Get main content (remove script, style tags)
        for script in soup(["script", "style"]):
            script.decompose()
        text_content = soup.get_text()
        
        # Check for relevant keywords
        all_text = f"{title_text} {text_content}"
        found_keywords = has_relevant_keywords(all_text, config['keywords'])
        
        if found_keywords:
            print(f"   âœ… TÃ¬m tháº¥y {len(found_keywords)} tá»« khÃ³a liÃªn quan:")
            for kw in found_keywords[:5]:  # Show first 5 keywords
                print(f"      - {kw}")
            if len(found_keywords) > 5:
                print(f"      ... vÃ  {len(found_keywords)-5} tá»« khÃ³a khÃ¡c")
            return True
        else:
            print(f"   âš ï¸  KhÃ´ng tÃ¬m tháº¥y tá»« khÃ³a liÃªn quan nÃ o")
            return False
            
    except Exception as e:
        print(f"   âŒ Lá»—i khi fetch URL: {e}")
        return False

def main():
    """Main function"""
    print("ğŸš€ Test cáº¥u hÃ¬nh crawler má»›i cho .gov.vn")
    print("=" * 50)
    
    # Load config
    config = load_config()
    
    print(f"ğŸ“‹ Cáº¥u hÃ¬nh Ä‘Ã£ load:")
    print(f"   - {len(config['domains'])} domains Ä‘Æ°á»£c phÃ©p")
    print(f"   - {len(config['keywords'])} tá»« khÃ³a")
    print(f"   - {len(config['seeds'])} URL seeds")
    print(f"   - {len(config['url_regex'])} URL regex patterns")
    
    # Test some seed URLs
    print(f"\nğŸ§ª Test má»™t sá»‘ URL seeds:")
    successful_urls = []
    
    # Test first few seeds
    test_seeds = config['seeds'][:5]  # Test first 5 seeds
    
    for url in test_seeds:
        if test_url(url, config):
            successful_urls.append(url)
    
    print(f"\nğŸ“Š Káº¿t quáº£:")
    print(f"   - ÄÃ£ test: {len(test_seeds)} URLs")
    print(f"   - ThÃ nh cÃ´ng: {len(successful_urls)} URLs")
    print(f"   - Tá»· lá»‡ thÃ nh cÃ´ng: {len(successful_urls)/len(test_seeds)*100:.1f}%")
    
    if successful_urls:
        print(f"\nâœ… URLs thÃ nh cÃ´ng:")
        for url in successful_urls:
            print(f"   - {url}")
    
    return len(successful_urls)

if __name__ == "__main__":
    result = main()
    print(f"\nğŸ HoÃ n thÃ nh test vá»›i {result} URLs thÃ nh cÃ´ng!")