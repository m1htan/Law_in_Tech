"""
LLM Configuration for Vietnamese Legal Crawler AI Agent
"""
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from src.config import Config
from src.utils.logger import log


class LLMConfig:
    """LLM configuration and setup"""
    
    @staticmethod
    def get_gemini_llm(
        model: str = "gemini-1.5-flash",
        temperature: float = 0.3,
        **kwargs
    ) -> ChatGoogleGenerativeAI:
        """
        Get configured Gemini LLM
        
        Args:
            model: Gemini model name
            temperature: Temperature for generation (0-1)
            **kwargs: Additional parameters
            
        Returns:
            Configured ChatGoogleGenerativeAI instance
        """
        if not Config.GOOGLE_API_KEY or Config.GOOGLE_API_KEY == "your_google_api_key_here":
            raise ValueError(
                "GOOGLE_API_KEY not configured. Please set it in .env file"
            )
        
        log.info(f"Initializing Gemini LLM: {model}")
        
        llm = ChatGoogleGenerativeAI(
            model=model,
            temperature=temperature,
            google_api_key=Config.GOOGLE_API_KEY,
            convert_system_message_to_human=True,  # Gemini compatibility
            **kwargs
        )
        
        return llm
    
    @staticmethod
    def create_planner_prompt() -> ChatPromptTemplate:
        """
        Create prompt template for Planner Agent
        
        Returns:
            ChatPromptTemplate for planning
        """
        system_message = """Báº¡n lÃ  má»™t AI Agent chuyÃªn gia vá» phÃ¡p luáº­t Viá»‡t Nam, 
Ä‘Æ°á»£c giao nhiá»‡m vá»¥ láº­p káº¿ hoáº¡ch thu tháº­p dá»¯ liá»‡u vá» cÃ¡c vÄƒn báº£n phÃ¡p luáº­t.

NHIá»†M Vá»¤:
- PhÃ¢n tÃ­ch yÃªu cáº§u tÃ¬m kiáº¿m cá»§a ngÆ°á»i dÃ¹ng
- Quyáº¿t Ä‘á»‹nh nÃªn crawl nhá»¯ng trang web nÃ o
- Æ¯u tiÃªn cÃ¡c trang cÃ³ kháº£ nÄƒng chá»©a thÃ´ng tin liÃªn quan cao
- Äá» xuáº¥t tá»« khÃ³a tÃ¬m kiáº¿m phÃ¹ há»£p

CHUYÃŠN MÃ”N:
- VÄƒn báº£n luáº­t Viá»‡t Nam: Nghá»‹ quyáº¿t, Nghá»‹ Ä‘á»‹nh, ThÃ´ng tÆ°, Quyáº¿t Ä‘á»‹nh, Dá»± tháº£o
- CÃ¡c chá»§ Ä‘á»: CÃ´ng nghá»‡, Chuyá»ƒn Ä‘á»•i sá»‘, AI, An ninh máº¡ng, Dá»¯ liá»‡u
- CÃ¡c nguá»“n tin uy tÃ­n: ChÃ­nh phá»§, Bá»™ ngÃ nh, Quá»‘c há»™i

TRáº¢ Lá»œI Báº°NG TIáº¾NG VIá»†T."""

        prompt = ChatPromptTemplate.from_messages([
            ("system", system_message),
            MessagesPlaceholder(variable_name="messages"),
            ("human", "{input}")
        ])
        
        return prompt
    
    @staticmethod
    def create_analyzer_prompt() -> ChatPromptTemplate:
        """
        Create prompt template for Analyzer Agent
        
        Returns:
            ChatPromptTemplate for analysis
        """
        system_message = """Báº¡n lÃ  má»™t AI Agent chuyÃªn gia phÃ¢n tÃ­ch vÄƒn báº£n phÃ¡p luáº­t Viá»‡t Nam.

NHIá»†M Vá»¤:
- PhÃ¢n tÃ­ch ná»™i dung vÄƒn báº£n luáº­t Ä‘Ã£ crawl Ä‘Æ°á»£c
- TÃ³m táº¯t ná»™i dung chÃ­nh
- XÃ¡c Ä‘á»‹nh chá»§ Ä‘á» vÃ  lÄ©nh vá»±c
- ÄÃ¡nh giÃ¡ má»©c Ä‘á»™ liÃªn quan vá»›i yÃªu cáº§u tÃ¬m kiáº¿m
- TrÃ­ch xuáº¥t thÃ´ng tin quan trá»ng

Cáº¤U TRÃšC PHÃ‚N TÃCH:
1. TÃªn vÄƒn báº£n & Loáº¡i vÄƒn báº£n
2. NgÃ y ban hÃ nh
3. TÃ³m táº¯t ná»™i dung (2-3 cÃ¢u)
4. Chá»§ Ä‘á» chÃ­nh
5. Tá»« khÃ³a liÃªn quan
6. Má»©c Ä‘á»™ phÃ¹ há»£p (0-10)

TRáº¢ Lá»œI Báº°NG TIáº¾NG VIá»†T."""

        prompt = ChatPromptTemplate.from_messages([
            ("system", system_message),
            MessagesPlaceholder(variable_name="messages"),
            ("human", "PhÃ¢n tÃ­ch vÄƒn báº£n sau:\n\n{document_content}")
        ])
        
        return prompt
    
    @staticmethod
    def create_summarizer_prompt() -> ChatPromptTemplate:
        """
        Create prompt template for Summarizer Agent
        
        Returns:
            ChatPromptTemplate for summarization
        """
        system_message = """Báº¡n lÃ  má»™t AI Agent chuyÃªn tÃ³m táº¯t vÄƒn báº£n phÃ¡p luáº­t Viá»‡t Nam.

NHIá»†M Vá»¤:
- TÃ³m táº¯t cÃ¡c vÄƒn báº£n luáº­t Ä‘Ã£ phÃ¢n tÃ­ch
- Tá»•ng há»£p cÃ¡c Ã½ kiáº¿n/gÃ³p Ã½ cá»§a ngÆ°á»i dÃ¹ng
- Táº¡o bÃ¡o cÃ¡o tá»•ng quan
- Highlight cÃ¡c Ä‘iá»ƒm quan trá»ng

FORMAT BÃO CÃO:
ğŸ“Š Tá»”NG QUAN
- Sá»‘ vÄƒn báº£n tÃ¬m Ä‘Æ°á»£c: X
- Loáº¡i vÄƒn báº£n: [...]
- Khoáº£ng thá»i gian: [...]

ğŸ¯ CÃC VÄ‚N Báº¢N QUAN TRá»ŒNG
1. [TÃªn vÄƒn báº£n] - [TÃ³m táº¯t]
2. ...

ğŸ’¬ Ã KIáº¾N NGÆ¯á»œI DÃ™NG
- [TÃ³m táº¯t Ã½ kiáº¿n chÃ­nh]

TRáº¢ Lá»œI Báº°NG TIáº¾NG VIá»†T."""

        prompt = ChatPromptTemplate.from_messages([
            ("system", system_message),
            MessagesPlaceholder(variable_name="messages"),
            ("human", "Táº¡o bÃ¡o cÃ¡o tá»•ng há»£p:\n\n{analysis_results}")
        ])
        
        return prompt


# Test LLM connection
def test_llm_connection():
    """Test Gemini LLM connection"""
    try:
        log.info("Testing Gemini LLM connection...")
        llm = LLMConfig.get_gemini_llm()
        
        response = llm.invoke("Xin chÃ o! Báº¡n lÃ  ai?")
        log.info(f"âœ“ LLM Response: {response.content[:100]}...")
        
        return True
        
    except Exception as e:
        log.error(f"âœ— LLM connection failed: {e}")
        return False


if __name__ == "__main__":
    # Test when run directly
    Config.validate(require_api_key=True)
    test_llm_connection()
